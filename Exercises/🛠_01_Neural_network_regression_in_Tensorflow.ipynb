{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgykhROugcVubTGv8Ha4+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farheenfathimaa/TensorFlow-DeepLearning/blob/main/%F0%9F%9B%A0_01_Neural_network_regression_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ›  01_Neural_network_regression_in_Tensorflow\n",
        "\n",
        "- Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "- Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "- Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "    - Building a larger model (how does one with 4 dense layers go?).\n",
        "    - Increasing the number of units in each layer.\n",
        "    - Lookup the documentation of Adam and find out what the first parameter is,what happens if you increase it by 10x?\n",
        "    - What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "- Import the Boston pricing dataset from TensorFlow `tf.keras.datasets` and model it."
      ],
      "metadata": {
        "id": "_8aAK71IqdCH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_uYO4a7CqgZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YG851JuWqiMt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iuuwt6AKql2h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize the dataset\n"
      ],
      "metadata": {
        "id": "-kTm6iKHqsJK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling our dummy data\n"
      ],
      "metadata": {
        "id": "Rf6UC4MOqvsr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?"
      ],
      "metadata": {
        "id": "pSNXKRwfq1fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model again with 4 Dense layers\n"
      ],
      "metadata": {
        "id": "s9FQ0fZWqyLG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm..Seems the model isn't improving maybe running for more epochs would do the magic. But let's split this into train and test set to help our model to generalize well.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rD0-OYwMq7SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into train and test splits\n"
      ],
      "metadata": {
        "id": "ZfmV-Es8q5Dp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's build the model from scratch"
      ],
      "metadata": {
        "id": "GDDQDDO0q_iE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating our model on the test data (unseen data)\n"
      ],
      "metadata": {
        "id": "Wt4dKhdKrBP-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the predictions of our model\n"
      ],
      "metadata": {
        "id": "PBJKvTP4rEIP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hNIIVwfHrFy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting our predictions with our target\n"
      ],
      "metadata": {
        "id": "-BAQzBhqrIwW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Our model is trying to predict the points but it's not doing a great job with it.\n",
        "\n",
        "Let's try couple of experiments and see how it goes."
      ],
      "metadata": {
        "id": "w7fTuDdGrM5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a model with 2 layers and fewer units\n"
      ],
      "metadata": {
        "id": "9e4Aym1OrJp4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building our model with 3 layers and with more hidden units\n"
      ],
      "metadata": {
        "id": "-crlFZgHrPqG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woooo! Look at that, but we shouldn't be excited lets evaluate on the test data."
      ],
      "metadata": {
        "id": "2gSNFeQ1rVMl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YH9ghWgdrSeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome! This is what we want error should be loss. Let's plot our predictions with targets!"
      ],
      "metadata": {
        "id": "I11_AHgwrXkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n"
      ],
      "metadata": {
        "id": "3v3o93cGrZax"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4eSEB6HrbGS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at that! Our model has predicted every test data correctly. You can't spot a green dot (test data) it's because our predictions (red dot) overlapped.\n",
        "\n",
        "Our model is doing a perfect job!\n",
        "\n",
        "## Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "- Building a larger model (how does one with 4 dense layers go?).\n",
        "- Increasing the number of units in each layer.\n",
        "- Lookup the documentation of Adam and find out what the first parameter is,what happens if you increase it by 10x?\n",
        "- What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "\n",
        "### Building a larger model (how does one with 4 dense layers go?)"
      ],
      "metadata": {
        "id": "9bqvi8IIrfH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's download the data\n"
      ],
      "metadata": {
        "id": "6UTvRLx2rdlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our insurance data has 1338 rows and 7 columns"
      ],
      "metadata": {
        "id": "130JtVvmruNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking into the data\n"
      ],
      "metadata": {
        "id": "UaCsI3TGruxj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have some categorical variables, let's convert those columns into numerial used pandas."
      ],
      "metadata": {
        "id": "hdCBhpYCrzKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn categorical into numbers\n"
      ],
      "metadata": {
        "id": "rGSTF9VWrwgj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into X and Y\n"
      ],
      "metadata": {
        "id": "NsIxV0Pdr5qw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating train and test split\n"
      ],
      "metadata": {
        "id": "18mMzQ4Pr90L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model with 4 dense layers and more units\n"
      ],
      "metadata": {
        "id": "Om1uIwDOr-ku"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lookup the documentation of Adam and find out what the first parameter is,what happens if you increase it by 10x?\n",
        "\n",
        "And running for 400 epochs"
      ],
      "metadata": {
        "id": "-3jqf264sEg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's tweak the Adam Optimizer's learning rate\n"
      ],
      "metadata": {
        "id": "iVLss3DEsBvS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n"
      ],
      "metadata": {
        "id": "AxrLWcDXsHXs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot the loss curve Vs Epochs\n"
      ],
      "metadata": {
        "id": "0VazF4UcsKak"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems even increasing the learning rate and the number of epochs the model isn't performing an greater level.\n",
        "\n",
        "## Import the Boston pricing dataset from TensorFlow `tf.keras.datasets` and model it."
      ],
      "metadata": {
        "id": "RF0PSQVesPtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the boston datasets from tensorflow datasets\n"
      ],
      "metadata": {
        "id": "ChaVGe6ysMBp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkin the shape of our data\n"
      ],
      "metadata": {
        "id": "GJ45IfaWstDH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This datasets is numpy array format and it's normalized."
      ],
      "metadata": {
        "id": "BTvPkDbRsyH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's build a model\n"
      ],
      "metadata": {
        "id": "sNi7GIUQsvh5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's evaluate on the test data\n"
      ],
      "metadata": {
        "id": "015GGTihs0pm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the loss Vs Epoch\n"
      ],
      "metadata": {
        "id": "lIWHRTQhs20j"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright we're done solving Exercise of the modeule Neural Network Regression with TensorFlow."
      ],
      "metadata": {
        "id": "SIkAV4OKs7L5"
      }
    }
  ]
}